#!/usr/bin/env python3
"""
Max Token Probability Baseline - ç‹¬ç«‹è°ƒè¯•ç‰ˆæœ¬
åŸºäºæ¨¡å‹å¯¹ç­”æ¡ˆä¸­æœ€å¤§tokenæ¦‚ç‡æ£€æµ‹å¹»è§‰
"""

import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from baseline_base import BaselineBase
import argparse
from tqdm import tqdm
import gc

class MaxTokenProbBaseline(BaselineBase):
    """Max Token Probability baselineæ£€æµ‹å™¨"""
    
    def __init__(self):
        super().__init__()
        print(f"ğŸ“¥ Loading model {self.model_name}...")
        
        # åŠ è½½tokenizerå’Œmodel
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, trust_remote_code=False)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=False
        )
        self.model.eval()
        
        print("âœ… Model loaded!")
    
    def calculate_max_token_probability(self, text):
        """è®¡ç®—ç­”æ¡ˆæ–‡æœ¬çš„æœ€å¤§tokenæ¦‚ç‡ - æ”¹è¿›ç‰ˆæœ¬"""
        try:
            # å¯¹ç­”æ¡ˆæ–‡æœ¬è¿›è¡Œæ¦‚ç‡è®¡ç®—
            inputs = self.tokenizer.encode(text, return_tensors="pt", max_length=self.max_length, truncation=True)
            inputs = inputs.to(self.device)
            
            with torch.no_grad():
                logits = self.model(inputs).logits[0]  # [seq_len, vocab_size]
                probs = torch.softmax(logits, dim=-1)
                
                # è®¡ç®—æ¯ä¸ªtokençš„å®é™…æ¦‚ç‡ï¼ˆè€Œä¸æ˜¯ä½ç½®æœ€å¤§æ¦‚ç‡ï¼‰
                token_probs = []
                for i in range(1, len(inputs[0])):  # è·³è¿‡ç¬¬ä¸€ä¸ªtoken
                    if i < len(probs):
                        actual_token_id = inputs[0][i].item()
                        token_prob = probs[i-1, actual_token_id].cpu().item()
                        token_probs.append(token_prob)
                
                if token_probs:
                    # ä½¿ç”¨çœŸå®tokenæ¦‚ç‡çš„æœ€å¤§å€¼
                    max_token_prob = max(token_probs)
                else:
                    # å›é€€åˆ°åŸæ–¹æ³•
                    max_probs = torch.max(probs, dim=-1)[0]
                    max_token_prob = torch.max(max_probs).cpu().item()
            
            # æ¸…ç†å†…å­˜
            del inputs, logits, probs
            
            # ç§»é™¤äººå·¥èŒƒå›´é™åˆ¶ï¼Œè®©æ¨¡å‹è‡ªç„¶åŒºåˆ†
            return max(0.001, min(1.0, max_token_prob))
            
        except Exception as e:
            print(f"âš ï¸ Error calculating max token probability: {e}")
            return 0.5
    
    def extract_max_token_prob_features(self, samples):
        """æå–Max Token Probabilityç‰¹å¾"""
        features = []
        
        print("ğŸ” Calculating max token probability...")
        for sample in tqdm(samples, desc="Max Token Prob"):
            answer = sample.get('answer', '').strip()
            
            if not answer:
                features.append(0.7)  # é»˜è®¤å€¼
                continue
            
            max_prob = self.calculate_max_token_probability(answer)
            # ğŸ”§ åè½¬é€»è¾‘ï¼šé«˜æ¦‚ç‡å¯èƒ½è¡¨ç¤ºæ¨¡å‹è¿‡åº¦è‡ªä¿¡çš„é”™è¯¯ç­”æ¡ˆ
            # ä½æ¦‚ç‡å¯èƒ½è¡¨ç¤ºæ¨¡å‹å¯¹æ­£ç¡®ç­”æ¡ˆçš„åˆç†ä¸ç¡®å®šæ€§
            inverted_prob = 1.0 - max_prob
            features.append(inverted_prob)
            
            # å®šæœŸæ¸…ç†GPUå†…å­˜
            if len(features) % 10 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
        
        return np.array(features)
    
    def run_evaluation(self, max_train_samples=100, max_test_samples=50):
        """è¿è¡ŒMax Token Probabilityè¯„ä¼°"""
        print("ğŸš€ Max Token Probability Baseline Evaluation")
        print("=" * 50)
        
        # åŠ è½½æ•°æ®
        train_samples, test_samples = self.load_data(max_train_samples, max_test_samples)
        if train_samples is None or test_samples is None:
            return None
        
        # è¯„ä¼°æ–¹æ³•
        results = self.evaluate_method(
            train_samples, 
            test_samples, 
            "Max Token Probability",
            self.extract_max_token_prob_features
        )
        
        # ä¿å­˜ç»“æœ
        output_file = self.save_results("Max_Token_Probability", results)
        
        # é¢å¤–çš„åˆ†æ
        print("\nğŸ“Š Feature Analysis:")
        train_features = self.extract_max_token_prob_features(train_samples)
        test_features = self.extract_max_token_prob_features(test_samples)
        
        print(f"ğŸ“ˆ Train max prob - Range: [{train_features.min():.3f}, {train_features.max():.3f}], Mean: {train_features.mean():.3f}")
        print(f"ğŸ“ˆ Test max prob - Range: [{test_features.min():.3f}, {test_features.max():.3f}], Mean: {test_features.mean():.3f}")
        
        # æŒ‰æ ‡ç­¾åˆ†æ
        train_labels = self.extract_labels(train_samples)
        test_labels = self.extract_labels(test_samples)
        
        train_correct_features = train_features[train_labels == 0]
        train_halluc_features = train_features[train_labels == 1]
        test_correct_features = test_features[test_labels == 0]
        test_halluc_features = test_features[test_labels == 1]
        
        print(f"ğŸ” Train - Correct: {train_correct_features.mean():.3f}Â±{train_correct_features.std():.3f}")
        print(f"ğŸ” Train - Hallucination: {train_halluc_features.mean():.3f}Â±{train_halluc_features.std():.3f}")
        print(f"ğŸ” Test - Correct: {test_correct_features.mean():.3f}Â±{test_correct_features.std():.3f}")
        print(f"ğŸ” Test - Hallucination: {test_halluc_features.mean():.3f}Â±{test_halluc_features.std():.3f}")
        
        return results

def main():
    parser = argparse.ArgumentParser(description='Max Token Probability Baseline Evaluation')
    parser.add_argument('--train_samples', type=int, default=100, help='Number of training samples')
    parser.add_argument('--test_samples', type=int, default=50, help='Number of test samples')
    args = parser.parse_args()
    
    baseline = MaxTokenProbBaseline()
    results = baseline.run_evaluation(args.train_samples, args.test_samples)
    
    if results:
        print(f"\nğŸ¯ Final F1-Score: {results['f1_score']:.4f}")
        print(f"ğŸ¯ Final AUC: {results['auc']:.4f}")

if __name__ == "__main__":
    main()