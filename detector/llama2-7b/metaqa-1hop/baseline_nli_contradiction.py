#!/usr/bin/env python3
"""
NLI-based Contradiction Detection Baseline - ç‹¬ç«‹è°ƒè¯•ç‰ˆæœ¬
åŸºäºè‡ªç„¶è¯­è¨€æ¨ç†æ£€æµ‹é—®é¢˜ä¸ç­”æ¡ˆä¹‹é—´çš„çŸ›ç›¾æ¥è¯†åˆ«å¹»è§‰
"""

import numpy as np
import torch
from transformers import pipeline
from baseline_base import BaselineBase
import argparse
from tqdm import tqdm
import gc

class NLIContradictionBaseline(BaselineBase):
    """NLI-based Contradiction Detection baselineæ£€æµ‹å™¨"""
    
    def __init__(self):
        super().__init__()
        print("ğŸ“¥ Loading NLI model for contradiction detection...")
        
        # åŠ è½½NLI pipeline
        try:
            self.nli_pipeline = pipeline(
                "text-classification",
                model="facebook/bart-large-mnli",
                device=0 if torch.cuda.is_available() else -1
            )
            print("âœ… NLI model loaded successfully!")
        except Exception as e:
            print(f"âŒ Error loading NLI model: {e}")
            raise e
    
    def calculate_nli_contradiction_score(self, question, answer):
        """è®¡ç®—é—®é¢˜ä¸ç­”æ¡ˆä¹‹é—´çš„çŸ›ç›¾åˆ†æ•°"""
        if not question or not answer:
            return 0.0  # æ— å†…å®¹æ—¶é»˜è®¤æ— çŸ›ç›¾
        
        try:
            # æ„å»ºNLIè¾“å…¥ï¼šé—®é¢˜ä½œä¸ºå‰æï¼Œç­”æ¡ˆä½œä¸ºå‡è®¾
            premise = question.strip()
            hypothesis = answer.strip()
            
            # ä½¿ç”¨NLIæ¨¡å‹è¿›è¡Œæ¨ç†
            result = self.nli_pipeline(f"{premise} [SEP] {hypothesis}")
            
            # æå–çŸ›ç›¾æ¦‚ç‡
            contradiction_score = 0.0
            for item in result:
                if item['label'].upper() == 'CONTRADICTION':
                    contradiction_score = item['score']
                    break
            
            # è¿”å›åŸå§‹NLIæ¨¡å‹è¾“å‡ºï¼Œä¸åŠ ä»»ä½•äººå·¥ä¿®æ”¹
            return float(contradiction_score)
            
        except Exception as e:
            print(f"âš ï¸ Error in NLI contradiction detection: {e}")
            return 0.0
    
    def extract_nli_contradiction_features(self, samples):
        """æå–NLI Contradictionç‰¹å¾"""
        features = []
        
        print("ğŸ” Calculating NLI contradiction scores...")
        for sample in tqdm(samples, desc="NLI Contradiction"):
            question = sample.get('question', '')
            answer = sample.get('answer', '')
            
            contradiction_score = self.calculate_nli_contradiction_score(question, answer)
            features.append(contradiction_score)
            
            # å®šæœŸæ¸…ç†GPUå†…å­˜
            if len(features) % 20 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
        
        return np.array(features)
    
    def run_evaluation(self, max_train_samples=100, max_test_samples=50):
        """è¿è¡ŒNLI Contradictionè¯„ä¼°"""
        print("ğŸš€ NLI-based Contradiction Detection Baseline Evaluation")
        print("=" * 60)
        
        # åŠ è½½æ•°æ®
        train_samples, test_samples = self.load_data(max_train_samples, max_test_samples)
        if train_samples is None or test_samples is None:
            return None
        
        # è¯„ä¼°æ–¹æ³•
        results = self.evaluate_method(
            train_samples, 
            test_samples, 
            "NLI-based Contradiction Detection",
            self.extract_nli_contradiction_features
        )
        
        # ä¿å­˜ç»“æœ
        output_file = self.save_results("NLI_based_Contradiction_Detection", results)
        
        # é¢å¤–çš„åˆ†æ
        print("\nğŸ“Š Feature Analysis:")
        train_features = self.extract_nli_contradiction_features(train_samples)
        test_features = self.extract_nli_contradiction_features(test_samples)
        
        print(f"ğŸ“ˆ Train contradiction - Range: [{train_features.min():.3f}, {train_features.max():.3f}], Mean: {train_features.mean():.3f}")
        print(f"ğŸ“ˆ Test contradiction - Range: [{test_features.min():.3f}, {test_features.max():.3f}], Mean: {test_features.mean():.3f}")
        
        # æŒ‰æ ‡ç­¾åˆ†æ
        train_labels = self.extract_labels(train_samples)
        test_labels = self.extract_labels(test_samples)
        
        train_correct_features = train_features[train_labels == 0]
        train_halluc_features = train_features[train_labels == 1]
        test_correct_features = test_features[test_labels == 0]
        test_halluc_features = test_features[test_labels == 1]
        
        print(f"ğŸ” Train - Correct: {train_correct_features.mean():.3f}Â±{train_correct_features.std():.3f}")
        print(f"ğŸ” Train - Hallucination: {train_halluc_features.mean():.3f}Â±{train_halluc_features.std():.3f}")
        print(f"ğŸ” Test - Correct: {test_correct_features.mean():.3f}Â±{test_correct_features.std():.3f}")
        print(f"ğŸ” Test - Hallucination: {test_halluc_features.mean():.3f}Â±{test_halluc_features.std():.3f}")
        
        # æ˜¾ç¤ºä¸€äº›æ ·æœ¬åˆ†æ
        print("\nğŸ” Sample Analysis:")
        for i, sample in enumerate(train_samples[:3]):
            question = sample.get('question', '')
            answer = sample.get('answer', '')
            label = "Correct" if train_labels[i] == 0 else "Hallucination"
            contradiction_score = train_features[i]
            
            print(f"  Sample {i+1} ({label}):")
            print(f"    Question: {question[:80]}...")
            print(f"    Answer: {answer[:80]}...")
            print(f"    Contradiction Score: {contradiction_score:.3f}")
            print()
        
        return results

def main():
    parser = argparse.ArgumentParser(description='NLI-based Contradiction Detection Baseline Evaluation')
    parser.add_argument('--train_samples', type=int, default=100, help='Number of training samples')
    parser.add_argument('--test_samples', type=int, default=50, help='Number of test samples')
    args = parser.parse_args()
    
    baseline = NLIContradictionBaseline()
    results = baseline.run_evaluation(args.train_samples, args.test_samples)
    
    if results:
        print(f"\nğŸ¯ Final F1-Score: {results['f1_score']:.4f}")
        print(f"ğŸ¯ Final AUC: {results['auc']:.4f}")

if __name__ == "__main__":
    main()