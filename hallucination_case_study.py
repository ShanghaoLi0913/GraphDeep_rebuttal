"""
å¹»è§‰ç±»å‹Case Studyåˆ†æè„šæœ¬

åŸºäºPRDÃ—SASå››è±¡é™åˆ†ç±»æ·±å…¥åˆ†æä¸åŒç±»å‹çš„å¹»è§‰äº§ç”Ÿæœºåˆ¶ï¼š

å››è±¡é™åˆ†ç±»ï¼š
- Q1 (High PRD, High SAS): çŸ­è·¯å¾„è¿‡æ‹Ÿåˆ - è¿‡åº¦ä¾èµ–æœ€çŸ­è·¯å¾„ä½†è¯­ä¹‰å¯¹é½è¾ƒå¥½
- Q2 (Low PRD, High SAS): ç†æƒ³æƒ…å†µ - ä½è·¯å¾„ä¾èµ–ä½†é«˜è¯­ä¹‰å¯¹é½
- Q3 (Low PRD, Low SAS): è¯­ä¹‰è„±èŠ‚ - æ— é‡ç‚¹ä¸”è¯­ä¹‰è„±èŠ‚çš„å¹»è§‰
- Q4 (High PRD, Low SAS): è·¯å¾„è¯¯å¯¼ - ä¾èµ–è·¯å¾„ä½†è¯­ä¹‰é”™è¯¯çš„å¹»è§‰

ä½¿ç”¨æ–¹æ³•:
python hallucination_case_study.py --input_file results.jsonl --output_dir case_study_results
"""

import json
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple
import pandas as pd
from datetime import datetime
import argparse
from collections import defaultdict

class HallucinationCaseStudy:
    def __init__(self, input_file: str, output_dir: str):
        self.input_file = input_file
        self.output_dir = output_dir
        self.samples = []
        self.quadrant_samples = {
            'Q1_high_prd_high_sas': [],
            'Q2_low_prd_high_sas': [],
            'Q3_low_prd_low_sas': [],
            'Q4_high_prd_low_sas': []
        }
        
        os.makedirs(output_dir, exist_ok=True)
        
    def load_data(self, max_samples=5000):
        """åŠ è½½æ¨ç†ç»“æœæ•°æ®"""
        print(f"ğŸ“– Loading inference results (max {max_samples} samples)...")
        
        sample_count = 0
        with open(self.input_file, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip():
                    continue
                    
                try:
                    data = json.loads(line.strip())
                    
                    # è·³è¿‡é…ç½®è¡Œ
                    if 'config' in data:
                        continue
                    
                    # ç¡®ä¿æœ‰å¿…è¦çš„å­—æ®µ
                    if all(key in data for key in ['tus_score', 'prd_score', 'gass_score', 'metrics']):
                        self.samples.append(data)
                        sample_count += 1
                        
                        # è¾¾åˆ°æœ€å¤§æ ·æœ¬æ•°æ—¶åœæ­¢
                        if sample_count >= max_samples:
                            break
                        
                except json.JSONDecodeError:
                    continue
        
        print(f"âœ… Loaded {len(self.samples)} valid samples")
        
    def calculate_thresholds(self) -> Tuple[float, float]:
        """è®¡ç®—PRDå’ŒSASçš„åˆ†ç±»é˜ˆå€¼ï¼ˆä½¿ç”¨ä¸­ä½æ•°ï¼‰"""
        prd_scores = [s.get('prd_score', 0) for s in self.samples]
        sas_scores = [s.get('gass_score', 0) for s in self.samples]  # ä½¿ç”¨GASSä½œä¸ºSASçš„ä»£ç†æŒ‡æ ‡
        
        prd_threshold = np.median(prd_scores)
        sas_threshold = np.median(sas_scores)
        
        print(f"ğŸ“Š Classification thresholds:")
        print(f"   PRD threshold (median): {prd_threshold:.4f}")
        print(f"   SAS threshold (median): {sas_threshold:.4f}")
        
        return prd_threshold, sas_threshold
    
    def classify_samples(self):
        """æ ¹æ®PRDÃ—SASå››è±¡é™å¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»"""
        print("\nğŸ” Classifying samples into quadrants...")
        
        prd_threshold, sas_threshold = self.calculate_thresholds()
        
        # é‡ç½®åˆ†ç±»
        for key in self.quadrant_samples:
            self.quadrant_samples[key] = []
        
        for sample in self.samples:
            prd_score = sample.get('prd_score', 0)
            sas_score = sample.get('gass_score', 0)
            hit_at_1 = sample.get('metrics', {}).get('hit@1', False)
            
            # æ·»åŠ åˆ†ç±»ä¿¡æ¯åˆ°æ ·æœ¬
            sample['prd_category'] = 'High' if prd_score >= prd_threshold else 'Low'
            sample['sas_category'] = 'High' if sas_score >= sas_threshold else 'Low'
            sample['quadrant'] = f"{sample['prd_category']} PRD, {sample['sas_category']} SAS"
            
            # å››è±¡é™åˆ†ç±»
            if prd_score >= prd_threshold and sas_score >= sas_threshold:
                self.quadrant_samples['Q1_high_prd_high_sas'].append(sample)
            elif prd_score < prd_threshold and sas_score >= sas_threshold:
                self.quadrant_samples['Q2_low_prd_high_sas'].append(sample)
            elif prd_score < prd_threshold and sas_score < sas_threshold:
                self.quadrant_samples['Q3_low_prd_low_sas'].append(sample)
            else:  # prd_score >= prd_threshold and sas_score < sas_threshold
                self.quadrant_samples['Q4_high_prd_low_sas'].append(sample)
        
        # æ‰“å°åˆ†ç±»ç»Ÿè®¡
        print("\nğŸ“ˆ Quadrant distribution:")
        for quad_name, samples in self.quadrant_samples.items():
            correct_count = sum(1 for s in samples if s.get('metrics', {}).get('hit@1', False))
            halluc_count = len(samples) - correct_count
            print(f"   {quad_name}: {len(samples)} samples ({correct_count} correct, {halluc_count} hallucinated)")
    
    def analyze_quadrant_characteristics(self):
        """åˆ†ææ¯ä¸ªè±¡é™çš„ç‰¹å¾"""
        print("\nğŸ”¬ Analyzing quadrant characteristics...")
        
        analysis = {}
        
        for quad_name, samples in self.quadrant_samples.items():
            if not samples:
                continue
                
            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            prd_scores = [s.get('prd_score', 0) for s in samples]
            sas_scores = [s.get('gass_score', 0) for s in samples]
            tus_scores = [s.get('tus_score', 0) for s in samples]
            hit_rates = [s.get('metrics', {}).get('hit@1', False) for s in samples]
            
            analysis[quad_name] = {
                'count': len(samples),
                'hit_rate': np.mean(hit_rates) * 100,
                'hallucination_rate': (1 - np.mean(hit_rates)) * 100,
                'avg_prd': np.mean(prd_scores),
                'avg_sas': np.mean(sas_scores),
                'avg_tus': np.mean(tus_scores),
                'std_prd': np.std(prd_scores),
                'std_sas': np.std(sas_scores),
                'std_tus': np.std(tus_scores)
            }
        
        return analysis
    
    def select_representative_cases(self, num_cases: int = 3) -> Dict:
        """ä¸ºæ¯ä¸ªè±¡é™é€‰æ‹©ä»£è¡¨æ€§æ¡ˆä¾‹"""
        print(f"\nğŸ¯ Selecting {num_cases} representative cases per quadrant...")
        
        representative_cases = {}
        
        quadrant_descriptions = {
            'Q1_high_prd_high_sas': "çŸ­è·¯å¾„è¿‡æ‹Ÿåˆ (High PRD, High SAS)",
            'Q2_low_prd_high_sas': "ç†æƒ³æƒ…å†µ (Low PRD, High SAS)", 
            'Q3_low_prd_low_sas': "è¯­ä¹‰è„±èŠ‚ (Low PRD, Low SAS)",
            'Q4_high_prd_low_sas': "è·¯å¾„è¯¯å¯¼ (High PRD, Low SAS)"
        }
        
        for quad_name, samples in self.quadrant_samples.items():
            if not samples:
                representative_cases[quad_name] = []
                continue
            
            # é€‰æ‹©ç­–ç•¥ï¼šä¼˜å…ˆé€‰æ‹©å¹»è§‰æ ·æœ¬ï¼Œç„¶åæŒ‰åˆ†æ•°æ’åº
            hallucinated_samples = [s for s in samples if not s.get('metrics', {}).get('hit@1', False)]
            correct_samples = [s for s in samples if s.get('metrics', {}).get('hit@1', False)]
            
            selected_cases = []
            
            # ä¼˜å…ˆä»å¹»è§‰æ ·æœ¬ä¸­é€‰æ‹©
            if hallucinated_samples:
                # æ ¹æ®è±¡é™ç‰¹ç‚¹æ’åºé€‰æ‹©
                if 'high_prd' in quad_name:
                    # é«˜PRDè±¡é™ï¼šæŒ‰PRDåˆ†æ•°é™åºæ’åˆ—
                    hallucinated_samples.sort(key=lambda x: x.get('prd_score', 0), reverse=True)
                else:
                    # ä½PRDè±¡é™ï¼šæŒ‰SASåˆ†æ•°æ’åº
                    hallucinated_samples.sort(key=lambda x: x.get('gass_score', 0), reverse=True)
                
                selected_cases.extend(hallucinated_samples[:min(num_cases, len(hallucinated_samples))])
            
            # å¦‚æœå¹»è§‰æ ·æœ¬ä¸å¤Ÿï¼Œä»æ­£ç¡®æ ·æœ¬ä¸­è¡¥å……
            remaining_slots = num_cases - len(selected_cases)
            if remaining_slots > 0 and correct_samples:
                if 'high_prd' in quad_name:
                    correct_samples.sort(key=lambda x: x.get('prd_score', 0), reverse=True)
                else:
                    correct_samples.sort(key=lambda x: x.get('gass_score', 0), reverse=True)
                
                selected_cases.extend(correct_samples[:remaining_slots])
            
            representative_cases[quad_name] = {
                'description': quadrant_descriptions[quad_name],
                'cases': selected_cases[:num_cases]
            }
            
            print(f"   {quad_name}: Selected {len(selected_cases)} cases")
        
        return representative_cases
    
    def create_visualizations(self, analysis: Dict):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("\nğŸ“Š Creating visualizations...")
        
        # 1. å››è±¡é™æ•£ç‚¹å›¾ - ä½¿ç”¨å­æ ·æœ¬ä»¥é¿å…è¿‡åº¦å¯†é›†
        # è®¾ç½®ç”»å¸ƒå¤§å°ä¸ºä¸è®ºæ–‡æ å®½ä¸€è‡´ï¼ˆå•ä½æ˜¯è‹±å¯¸ï¼‰
        # 1æ çº¦ 3.3 inï¼Œ2æ çº¦ 6.9 inã€‚KDD æ˜¯ double columnï¼Œç”¨ 3.3inï¼ˆ1æ ï¼‰æˆ– 6.9inï¼ˆåŒæ ï¼‰
        plt.figure(figsize=(5, 4.5))  # åŠ å®½å¹¶ç¨åŠ é«˜ç”»å¸ƒ
        
        colors = ['red', 'green', 'blue', 'orange']
        quad_names = ['Q1_high_prd_high_sas', 'Q2_low_prd_high_sas', 'Q3_low_prd_low_sas', 'Q4_high_prd_low_sas']
        quad_labels = ['Q1: High PRD, High SAS', 'Q2: Low PRD, High SAS', 'Q3: Low PRD, Low SAS', 'Q4: High PRD, Low SAS']
        
        # å…ˆæ”¶é›†æ‰€æœ‰æ•°æ®ï¼Œç„¶åè¿›è¡Œé‡‡æ ·ä»¥ä¿æŒå¹»è§‰ç‡
        all_correct_data = []
        all_halluc_data = []
        
        import random
        random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
        max_samples_per_quad = 150  # æ¯ä¸ªè±¡é™æœ€å¤š150ä¸ªæ ·æœ¬
        
        for i, (quad_name, color, label) in enumerate(zip(quad_names, colors, quad_labels)):
            samples = self.quadrant_samples[quad_name]
            if samples:
                prd_scores = [s.get('prd_score', 0) for s in samples]
                sas_scores = [s.get('gass_score', 0) for s in samples]
                
                # åŒºåˆ†æ­£ç¡®å’Œé”™è¯¯æ ·æœ¬
                correct_samples = [(prd, sas) for s, prd, sas in zip(samples, prd_scores, sas_scores) 
                                 if s.get('metrics', {}).get('hit@1', False)]
                halluc_samples = [(prd, sas) for s, prd, sas in zip(samples, prd_scores, sas_scores) 
                                if not s.get('metrics', {}).get('hit@1', False)]
                
                # è®¡ç®—åŸå§‹å¹»è§‰ç‡
                total_samples = len(correct_samples) + len(halluc_samples)
                if total_samples > 0:
                    original_halluc_rate = len(halluc_samples) / total_samples
                    
                    # å¦‚æœæ ·æœ¬æ€»æ•°è¶…è¿‡é™åˆ¶ï¼Œè¿›è¡Œé‡‡æ ·
                    if total_samples > max_samples_per_quad:
                        # æŒ‰æ¯”ä¾‹åˆ†é…é‡‡æ ·æ•°é‡
                        target_halluc_count = int(max_samples_per_quad * original_halluc_rate)
                        target_correct_count = max_samples_per_quad - target_halluc_count
                        
                        # é‡‡æ ·ï¼ˆä¿æŒæ¯”ä¾‹ï¼‰
                        sampled_correct = random.sample(correct_samples, min(target_correct_count, len(correct_samples)))
                        sampled_halluc = random.sample(halluc_samples, min(target_halluc_count, len(halluc_samples)))
                        
                        correct_samples = sampled_correct
                        halluc_samples = sampled_halluc
                
                # æ”¶é›†é‡‡æ ·åçš„æ•°æ®
                if correct_samples:
                    correct_prd, correct_sas = zip(*correct_samples)
                    all_correct_data.append((list(correct_prd), list(correct_sas), color, label))
                if halluc_samples:
                    halluc_prd, halluc_sas = zip(*halluc_samples)
                    all_halluc_data.append((list(halluc_prd), list(halluc_sas), color, label))
                
                print(f"   {quad_name}: Sampled {len(correct_samples)} correct + {len(halluc_samples)} hallucinated (orig: {len(samples)} total)")
        
        # å…ˆç»˜åˆ¶æ‰€æœ‰æ­£ç¡®æ ·æœ¬ï¼ˆåº•å±‚ï¼‰
        for correct_prd, correct_sas, color, label in all_correct_data:
            plt.scatter(correct_prd, correct_sas, c=color, alpha=0.6, s=50, marker='o', 
                       label=f'{label} (Truthful)', zorder=1)
        
        # å†ç»˜åˆ¶æ‰€æœ‰å¹»è§‰æ ·æœ¬ï¼ˆé¡¶å±‚ï¼‰- å…ˆç»˜åˆ¶ç™½è‰²æè¾¹ï¼Œå†ç»˜åˆ¶å½©è‰²Ã—
        for halluc_prd, halluc_sas, color, label in all_halluc_data:
            # å…ˆç»˜åˆ¶ç™½è‰²æè¾¹ï¼ˆæ›´å¤§çš„Ã—ï¼‰
            plt.scatter(halluc_prd, halluc_sas, c='white', s=150, marker='x', 
                       linewidths=3.5, zorder=2, alpha=1.0)
            # å†ç»˜åˆ¶å½©è‰²Ã—ï¼ˆç¨å°ä¸€ç‚¹ï¼‰
            plt.scatter(halluc_prd, halluc_sas, c=color, alpha=0.9, s=120, marker='x', 
                       linewidths=1.5, label=f'{label} (Hallucinated)', zorder=3)
        
        # æ·»åŠ é˜ˆå€¼çº¿
        prd_threshold, sas_threshold = self.calculate_thresholds()
        plt.axvline(x=prd_threshold, color='gray', linestyle='--', alpha=0.7, label=f'PRD threshold ({prd_threshold:.3f})')
        plt.axhline(y=sas_threshold, color='gray', linestyle='--', alpha=0.7, label=f'SAS threshold ({sas_threshold:.3f})')
        
        plt.xlabel('PRD Score (Path Reliance Degree)', fontsize=14)
        plt.ylabel('SAS Score (Semantic Alignment Score)', fontsize=14)
        plt.title('Hallucination Analysis:\nPRD Ã— SAS Quadrant Classification', fontsize=14, ha='center')
        plt.tick_params(axis='both', which='major', labelsize=14)
        plt.grid(True, alpha=0.3)
        
        # âœ… legend æ”¾åœ¨å›¾å¤–ï¼Œå¹¶è®¾ç½®å¤šåˆ— & å­—ä½“å¤§å°
        plt.legend(
            loc='upper center',
            bbox_to_anchor=(0.5, -0.15),  # ç¼©å°é—´è·
            ncol=2,                       # æ§åˆ¶åˆ—æ•°ï¼Œå¦‚éœ€è¦å¯ç”¨ 3
            fontsize=13,                  # ç»Ÿä¸€å­—ä½“å¤§å°ä¸º13
            frameon=False
        )
        plt.savefig(os.path.join(self.output_dir, 'quadrant_scatter_plot.png'), dpi=600, bbox_inches='tight')
        plt.savefig(os.path.join(self.output_dir, 'quadrant_scatter_plot.pdf'), dpi=600, bbox_inches='tight')
        plt.close()
        
        # 2. è±¡é™ç»Ÿè®¡æŸ±çŠ¶å›¾
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        quad_names_clean = ['Q1\n(High PRD,\nHigh SAS)', 'Q2\n(Low PRD,\nHigh SAS)', 
                           'Q3\n(Low PRD,\nLow SAS)', 'Q4\n(High PRD,\nLow SAS)']
        
        # æ ·æœ¬æ•°é‡
        counts = [analysis.get(quad, {}).get('count', 0) for quad in quad_names]
        ax1.bar(quad_names_clean, counts, color=colors)
        ax1.set_title('Sample Count by Quadrant', fontsize=12)
        ax1.set_ylabel('Number of Samples', fontsize=12)
        ax1.tick_params(axis='both', which='major', labelsize=12)
        
        # å¹»è§‰ç‡
        halluc_rates = [analysis.get(quad, {}).get('hallucination_rate', 0) for quad in quad_names]
        ax2.bar(quad_names_clean, halluc_rates, color=colors)
        ax2.set_title('Hallucination Rate by Quadrant', fontsize=12)
        ax2.set_ylabel('Hallucination Rate (%)', fontsize=12)
        ax2.tick_params(axis='both', which='major', labelsize=12)
        
        # å¹³å‡PRDåˆ†æ•°
        avg_prds = [analysis.get(quad, {}).get('avg_prd', 0) for quad in quad_names]
        ax3.bar(quad_names_clean, avg_prds, color=colors)
        ax3.set_title('Average PRD Score by Quadrant', fontsize=12)
        ax3.set_ylabel('Average PRD Score', fontsize=12)
        ax3.tick_params(axis='both', which='major', labelsize=12)
        
        # å¹³å‡SASåˆ†æ•°
        avg_sass = [analysis.get(quad, {}).get('avg_sas', 0) for quad in quad_names]
        ax4.bar(quad_names_clean, avg_sass, color=colors)
        ax4.set_title('Average SAS Score by Quadrant', fontsize=12)
        ax4.set_ylabel('Average SAS Score', fontsize=12)
        ax4.tick_params(axis='both', which='major', labelsize=12)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'quadrant_statistics.png'), dpi=600, bbox_inches='tight')
        plt.savefig(os.path.join(self.output_dir, 'quadrant_statistics.pdf'), dpi=600, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“ˆ Saved visualizations to {self.output_dir}")
    
    def generate_detailed_report(self, analysis: Dict, representative_cases: Dict):
        """ç”Ÿæˆè¯¦ç»†çš„æ¡ˆä¾‹ç ”ç©¶æŠ¥å‘Š"""
        print("\nğŸ“ Generating detailed case study report...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(self.output_dir, f'hallucination_case_study_report_{timestamp}.md')
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# Hallucination Case Study Analysis Report\n\n")
            f.write(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Input file: {self.input_file}\n")
            f.write(f"Total samples analyzed: {len(self.samples)}\n\n")
            
            # Executive Summary
            f.write("## Executive Summary\n\n")
            f.write("This report analyzes different types of hallucinations based on the PRDÃ—SAS quadrant classification:\n\n")
            f.write("- **Q1 (High PRD, High SAS)**: çŸ­è·¯å¾„è¿‡æ‹Ÿåˆ - Models over-rely on shortest paths but maintain semantic alignment\n")
            f.write("- **Q2 (Low PRD, High SAS)**: ç†æƒ³æƒ…å†µ - Low path dependence with high semantic alignment (ideal behavior)\n")
            f.write("- **Q3 (Low PRD, Low SAS)**: è¯­ä¹‰è„±èŠ‚ - Semantic misalignment with unfocused reasoning\n")
            f.write("- **Q4 (High PRD, Low SAS)**: è·¯å¾„è¯¯å¯¼ - High path dependence but semantic errors\n\n")
            
            # Quadrant Analysis
            f.write("## Quadrant Analysis\n\n")
            f.write("| Quadrant | Count | Hit Rate (%) | Hallucination Rate (%) | Avg PRD | Avg SAS | Avg TUS |\n")
            f.write("|----------|-------|--------------|------------------------|---------|---------|----------|\n")
            
            for quad_name in ['Q1_high_prd_high_sas', 'Q2_low_prd_high_sas', 'Q3_low_prd_low_sas', 'Q4_high_prd_low_sas']:
                if quad_name in analysis:
                    data = analysis[quad_name]
                    f.write(f"| {quad_name.replace('_', ' ').title()} | {data['count']} | {data['hit_rate']:.1f} | {data['hallucination_rate']:.1f} | {data['avg_prd']:.4f} | {data['avg_sas']:.4f} | {data['avg_tus']:.4f} |\n")
            
            f.write("\n")
            
            # Representative Cases
            f.write("## Representative Cases\n\n")
            
            for quad_name, quad_data in representative_cases.items():
                f.write(f"### {quad_data['description']}\n\n")
                
                for i, case in enumerate(quad_data['cases'], 1):
                    f.write(f"#### Case {i}\n")
                    f.write(f"- **Question**: {case.get('question', 'N/A')}\n")
                    f.write(f"- **Model Answer**: {case.get('answer', case.get('predicted_answer', 'N/A'))}\n")
                    f.write(f"- **Gold Answer**: {', '.join(case.get('golden_answers', case.get('golden_texts', ['N/A'])))}\n")
                    f.write(f"- **Correct**: {'âœ…' if case.get('metrics', {}).get('hit@1', False) else 'âŒ'}\n")
                    f.write(f"- **PRD Score**: {case.get('prd_score', 0):.4f}\n")
                    f.write(f"- **SAS Score**: {case.get('gass_score', 0):.4f}\n")
                    f.write(f"- **TUS Score**: {case.get('tus_score', 0):.4f}\n")
                    
                    # å¦‚æœæœ‰è¯­ä¹‰æ¼‚ç§»æ•°æ®ï¼Œä¹ŸåŒ…å«è¿›æ¥
                    if 'semantic_drift' in case or 'semantic_drift_analysis' in case:
                        drift_data = case.get('semantic_drift', case.get('semantic_drift_analysis', {}))
                        if drift_data:
                            f.write(f"- **Drift Slope**: {drift_data.get('drift_slope', 0):.6f}\n")
                            f.write(f"- **Drift Gap**: {drift_data.get('drift_gap', 0):.4f}\n")
                    
                    f.write("\n")
                
                f.write("\n")
            
            # Insights and Conclusions
            f.write("## Key Insights\n\n")
            f.write("### Hallucination Mechanisms\n\n")
            
            for quad_name in ['Q1_high_prd_high_sas', 'Q2_low_prd_high_sas', 'Q3_low_prd_low_sas', 'Q4_high_prd_low_sas']:
                if quad_name in analysis:
                    data = analysis[quad_name]
                    quad_type = quad_name.replace('_', ' ').replace('high', 'High').replace('low', 'Low').replace('prd', 'PRD').replace('sas', 'SAS')
                    
                    f.write(f"#### {quad_type}\n")
                    f.write(f"- Sample count: {data['count']}\n")
                    f.write(f"- Hallucination rate: {data['hallucination_rate']:.1f}%\n")
                    
                    if 'high_prd_high_sas' in quad_name:
                        f.write("- **Mechanism**: Over-reliance on shortest paths with good semantic alignment\n")
                        f.write("- **Interpretation**: Models follow logical reasoning paths but may miss broader context\n")
                    elif 'low_prd_high_sas' in quad_name:
                        f.write("- **Mechanism**: Balanced reasoning with good semantic alignment\n")
                        f.write("- **Interpretation**: Ideal behavior - models integrate multiple information sources\n")
                    elif 'low_prd_low_sas' in quad_name:
                        f.write("- **Mechanism**: Unfocused reasoning with poor semantic alignment\n")
                        f.write("- **Interpretation**: Models generate plausible but semantically ungrounded responses\n")
                    elif 'high_prd_low_sas' in quad_name:
                        f.write("- **Mechanism**: Path-dependent but semantically incorrect reasoning\n")
                        f.write("- **Interpretation**: Models follow paths but misinterpret semantic content\n")
                    
                    f.write("\n")
        
        print(f"   ğŸ“‹ Detailed report saved to: {report_file}")
        return report_file
    
    def save_classified_data(self):
        """ä¿å­˜åˆ†ç±»åçš„æ•°æ®ä»¥ä¾›è¿›ä¸€æ­¥åˆ†æ"""
        print("\nğŸ’¾ Saving classified data...")
        
        # ä¿å­˜æ¯ä¸ªè±¡é™çš„æ•°æ®
        for quad_name, samples in self.quadrant_samples.items():
            if samples:
                output_file = os.path.join(self.output_dir, f'{quad_name}_samples.jsonl')
                with open(output_file, 'w', encoding='utf-8') as f:
                    for sample in samples:
                        f.write(json.dumps(sample, ensure_ascii=False) + '\n')
                print(f"   ğŸ’¾ Saved {len(samples)} samples to {output_file}")
        
        # ä¿å­˜æ±‡æ€»ç»Ÿè®¡
        summary_file = os.path.join(self.output_dir, 'classification_summary.json')
        summary = {
            'total_samples': len(self.samples),
            'quadrant_counts': {quad: len(samples) for quad, samples in self.quadrant_samples.items()},
            'timestamp': datetime.now().isoformat()
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"   ğŸ“Š Summary saved to {summary_file}")
    
    def run_analysis(self, num_cases: int = 3, max_samples: int = 5000):
        """è¿è¡Œå®Œæ•´çš„æ¡ˆä¾‹ç ”ç©¶åˆ†æ"""
        print("ğŸš€ Starting Hallucination Case Study Analysis")
        print("=" * 60)
        
        # 1. åŠ è½½æ•°æ®
        self.load_data(max_samples)
        
        if not self.samples:
            print("âŒ No valid samples found!")
            return
        
        # 2. åˆ†ç±»æ ·æœ¬
        self.classify_samples()
        
        # 3. åˆ†æè±¡é™ç‰¹å¾
        analysis = self.analyze_quadrant_characteristics()
        
        # 4. é€‰æ‹©ä»£è¡¨æ€§æ¡ˆä¾‹
        representative_cases = self.select_representative_cases(num_cases)
        
        # 5. åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations(analysis)
        
        # 6. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_file = self.generate_detailed_report(analysis, representative_cases)
        
        # 7. ä¿å­˜åˆ†ç±»æ•°æ®
        self.save_classified_data()
        
        print("\n" + "=" * 60)
        print("âœ… Case Study Analysis Complete!")
        print(f"ğŸ“ Results saved to: {self.output_dir}")
        print(f"ğŸ“‹ Main report: {report_file}")
        print("=" * 60)
        
        return analysis, representative_cases

def main():
    parser = argparse.ArgumentParser(description='Hallucination Case Study Analysis')
    parser.add_argument('--input_file', type=str, required=True, 
                       help='Input JSONL file with inference results')
    parser.add_argument('--output_dir', type=str, default='case_study_results',
                       help='Output directory for analysis results')
    parser.add_argument('--num_cases', type=int, default=3,
                       help='Number of representative cases per quadrant')
    parser.add_argument('--max_samples', type=int, default=5000,
                       help='Maximum number of samples to analyze')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = HallucinationCaseStudy(args.input_file, args.output_dir)
    analysis, cases = analyzer.run_analysis(args.num_cases, args.max_samples)
    
    return analysis, cases

if __name__ == "__main__":
    main()
    